# ğŸ§  Sistema de InteligÃªncia Artificial Neural

## VisÃ£o Geral

Cada personagem possui sua prÃ³pria **Rede Neural** que controla:
- **Movimentos** (para onde ir)
- **Ataques** (quando atacar)
- **EstratÃ©gias** (fugir ou atacar)

As redes neurais **evoluem** atravÃ©s de **Algoritmo GenÃ©tico**:
1. Combates avaliam o desempenho
2. Melhores redes sobrevivem
3. ReproduÃ§Ã£o cria novas redes
4. MutaÃ§Ãµes trazem variedade
5. Nova geraÃ§Ã£o Ã© testada

---

## ğŸ—ï¸ Arquitetura da Rede Neural

### Camadas
```
Entrada (12 neurÃ´nios) â†’ Sensores do ambiente
    â†“
Oculta 1 (16 neurÃ´nios) â†’ Processamento
    â†“
Oculta 2 (8 neurÃ´nios) â†’ DecisÃ£o
    â†“
SaÃ­da (4 neurÃ´nios) â†’ AÃ§Ãµes
```

### Entrada - 12 Sensores

| # | Sensor | DescriÃ§Ã£o | NormalizaÃ§Ã£o |
|---|--------|-----------|--------------|
| 0 | pos_x | PosiÃ§Ã£o X | 0-1 (x/largura) |
| 1 | pos_y | PosiÃ§Ã£o Y | 0-1 (y/altura) |
| 2 | dir_inimigo_x | DireÃ§Ã£o X para inimigo | -1 a 1 |
| 3 | dir_inimigo_y | DireÃ§Ã£o Y para inimigo | -1 a 1 |
| 4 | dist_inimigo | DistÃ¢ncia normalizada | 0-1 |
| 5 | vida_propria | HP prÃ³prio | 0-1 |
| 6 | vida_inimigo | HP do inimigo mais prÃ³ximo | 0-1 |
| 7 | tem_arma | Arma equipada | 0 ou 1 |
| 8 | dist_borda_x | DistÃ¢ncia para borda X | 0-1 |
| 9 | dist_borda_y | DistÃ¢ncia para borda Y | 0-1 |
| 10 | num_inimigos | NÃºmero de inimigos vivos | 0-1 |
| 11 | forca_relativa | ForÃ§a prÃ³pria / mÃ©dia inimigos | 0-2+ |

### SaÃ­da - 4 AÃ§Ãµes

| # | AÃ§Ã£o | DescriÃ§Ã£o | InterpretaÃ§Ã£o |
|---|------|-----------|---------------|
| 0 | mover_x | Movimento horizontal | 0-1 â†’ -1 a 1 |
| 1 | mover_y | Movimento vertical | 0-1 â†’ -1 a 1 |
| 2 | atacar | Deve atacar | >0.5 = SIM |
| 3 | fugir | Deve fugir | >0.5 = inverte movimento |

---

## ğŸ§¬ Algoritmo GenÃ©tico

### Fluxo de EvoluÃ§Ã£o

```
GeraÃ§Ã£o N
    â†“
Combates (avaliaÃ§Ã£o)
    â†“
CÃ¡lculo de Fitness
    â†“
SeleÃ§Ã£o (torneio)
    â†“
Elitismo (melhores passam)
    â†“
Crossover (reproduÃ§Ã£o)
    â†“
MutaÃ§Ã£o (variaÃ§Ã£o)
    â†“
GeraÃ§Ã£o N+1
```

### Fitness (PontuaÃ§Ã£o)

```python
Fitness = Pontos Positivos - Pontos Negativos

Pontos Positivos:
+ VitÃ³ria: +1000
+ Dano causado: +1 por HP
+ Vida restante: +2 por HP

Pontos Negativos:
- Derrota: -500
- Dano recebido: -0.5 por HP
```

### Exemplo de Fitness

```
Personagem A:
- 3 vitÃ³rias, 1 derrota
- Causou 450 de dano
- Recebeu 300 de dano
- Vida mÃ©dia restante: 40 HP

Fitness = (3Ã—1000) - (1Ã—500) + 450 - (300Ã—0.5) + (40Ã—2)
        = 3000 - 500 + 450 - 150 + 80
        = 2880 pontos
```

### ParÃ¢metros de EvoluÃ§Ã£o

| ParÃ¢metro | Valor PadrÃ£o | DescriÃ§Ã£o |
|-----------|--------------|-----------|
| PopulaÃ§Ã£o | 20 | Redes por geraÃ§Ã£o |
| Taxa Elite | 20% | Melhores que passam direto |
| Taxa MutaÃ§Ã£o | 15% | Chance de sofrer mutaÃ§Ã£o |
| Intensidade MutaÃ§Ã£o | 0.3 | Quanto os pesos mudam |
| Tamanho Torneio | 3 | Candidatos na seleÃ§Ã£o |

---

## ğŸ’» Uso do Sistema

### 1. Criar Rede Neural

```python
from ia import RedeNeuralPersonagem

# Cria rede para personagem ID 1
rede = RedeNeuralPersonagem(
    personagem_id=1,
    camadas=[12, 16, 8, 4]  # entrada, oculta1, oculta2, saÃ­da
)
```

### 2. Decidir AÃ§Ã£o

```python
# Durante o jogo
acao = rede.decidir_acao(
    personagem=meu_personagem,
    outros_personagens=lista_inimigos,
    largura=800,
    altura=600
)

# acao contÃ©m:
# {'mover_x': -0.5, 'mover_y': 0.8, 'atacar': True, 'fugir': False}

# Aplicar movimento
meu_personagem.vx = acao['mover_x'] * meu_personagem.velocidade
meu_personagem.vy = acao['mover_y'] * meu_personagem.velocidade

# Atacar se necessÃ¡rio
if acao['atacar'] and meu_personagem.arma:
    meu_personagem.arma.disparar()
```

### 3. Treinar com Algoritmo GenÃ©tico

```python
from ia import TreinadorGenetico

# Criar treinador
treinador = TreinadorGenetico(
    tamanho_populacao=20,
    taxa_mutacao=0.15,
    taxa_elite=0.2
)

# PopulaÃ§Ã£o inicial
treinador.criar_populacao_inicial(personagem_id=1)

# Loop de treinamento
for geracao in range(100):
    # 1. Executar combates com cada rede
    resultados = executar_combates(treinador.populacao)
    
    # 2. Avaliar fitness
    treinador.avaliar_populacao(resultados)
    
    # 3. Salvar melhor
    if geracao % 10 == 0:
        treinador.salvar_melhor(personagem_id=1)
    
    # 4. Nova geraÃ§Ã£o
    treinador.nova_geracao()

# Salvar populaÃ§Ã£o final
treinador.salvar_populacao()
```

### 4. Salvar e Carregar

```python
# Salvar rede
rede.salvar("redes_neurais/minha_rede.json")

# Carregar rede
rede_carregada = RedeNeuralPersonagem.carregar(
    "redes_neurais/minha_rede.json"
)

# Usar rede carregada
acao = rede_carregada.decidir_acao(personagem, inimigos)
```

---

## ğŸ“Š Exemplos de Comportamento

### Comportamento Agressivo

```
Sensores:
- Inimigo prÃ³ximo
- Vida alta (>70%)
- Tem arma

AÃ§Ã£o da Rede:
- mover_x, mover_y â†’ Em direÃ§Ã£o ao inimigo
- atacar â†’ True
- fugir â†’ False

Resultado: Persegue e ataca
```

### Comportamento Defensivo

```
Sensores:
- Inimigo prÃ³ximo
- Vida baixa (<30%)
- Muitos inimigos

AÃ§Ã£o da Rede:
- mover_x, mover_y â†’ DireÃ§Ã£o aleatÃ³ria
- atacar â†’ False
- fugir â†’ True

Resultado: Foge para se recuperar
```

### Comportamento EstratÃ©gico

```
Sensores:
- Inimigo longe
- Vida mÃ©dia (50%)
- Perto da borda

AÃ§Ã£o da Rede:
- mover_x, mover_y â†’ Para o centro
- atacar â†’ False (economiza energia)
- fugir â†’ False

Resultado: Posicionamento tÃ¡tico
```

---

## ğŸ® IntegraÃ§Ã£o com o Jogo

### Modificar main_simulation.py

```python
# Carregar rede neural do personagem
if hasattr(personagem, 'rede_neural'):
    # IA controla
    acao = personagem.rede_neural.decidir_acao(
        personagem, personagens, WIDTH, HEIGHT
    )
    
    # Aplicar movimento
    personagem.vx = acao['mover_x'] * personagem.velocidade
    personagem.vy = acao['mover_y'] * personagem.velocidade
    
    # Atacar
    if acao['atacar'] and personagem.arma:
        # LÃ³gica de ataque
        pass
else:
    # Controle manual ou padrÃ£o
    pass
```

### Modificar PersonagemCreate.py

```python
# Ao criar personagem, cria tambÃ©m sua rede neural
from ia import RedeNeuralPersonagem

rede = RedeNeuralPersonagem(novo_id)
rede.salvar(f"redes_neurais/rede_personagem_{novo_id}.json")
```

---

## ğŸ“ˆ Progresso de Treinamento

### GeraÃ§Ãµes TÃ­picas

| GeraÃ§Ã£o | Fitness MÃ©dio | Comportamento |
|---------|---------------|---------------|
| 0-10 | 0-500 | Movimento aleatÃ³rio |
| 10-30 | 500-1500 | Aprende a evitar bordas |
| 30-60 | 1500-3000 | Persegue inimigos |
| 60-100 | 3000-5000 | EstratÃ©gias complexas |
| 100+ | 5000+ | Comportamento otimizado |

### ConvergÃªncia

```
Fitness
  ^
  |     /-----------  (convergiu)
  |    /
  |   /
  |  /
  | /
  |/___________________>
  0  20  40  60  80  100  GeraÃ§Ãµes
```

---

## ğŸ”§ Ajustes Finos

### Aumentar ExploraÃ§Ã£o

```python
# Mais mutaÃ§Ã£o, mais variedade
treinador.taxa_mutacao = 0.25

# Menor elite, mais renovaÃ§Ã£o
treinador.taxa_elite = 0.1
```

### Aumentar Estabilidade

```python
# Menos mutaÃ§Ã£o, mais conservador
treinador.taxa_mutacao = 0.05

# Maior elite, preserva bons genes
treinador.taxa_elite = 0.3
```

### Mudar Arquitetura

```python
# Rede mais profunda
rede = RedeNeuralPersonagem(
    personagem_id=1,
    camadas=[12, 32, 16, 8, 4]  # +1 camada oculta
)

# Rede mais larga
rede = RedeNeuralPersonagem(
    personagem_id=1,
    camadas=[12, 24, 24, 4]  # neurÃ´nios extras
)
```

---

## ğŸ¯ EstratÃ©gias AvanÃ§adas

### Co-EvoluÃ§Ã£o

Treinar mÃºltiplos personagens simultaneamente:
```python
# Cada personagem tem sua rede
redes = {
    1: RedeNeuralPersonagem(1),
    2: RedeNeuralPersonagem(2),
    3: RedeNeuralPersonagem(3)
}

# Combates entre todos
for p1 in redes:
    for p2 in redes:
        if p1 != p2:
            resultado = combate(redes[p1], redes[p2])
            # Atualizar fitness
```

### Transfer Learning

Usar rede treinada como base:
```python
# Carregar rede experiente
rede_base = RedeNeuralPersonagem.carregar("melhor_rede.json")

# Criar nova com mesma base
nova_rede = rede_base.clonar()
nova_rede.personagem_id = 2

# Pequena mutaÃ§Ã£o para especializar
nova_rede.mutar(taxa_mutacao=0.05, intensidade=0.1)
```

### Ensembles

Combinar vÃ¡rias redes:
```python
# 3 redes votam
redes = [rede1, rede2, rede3]
acoes = [r.decidir_acao(p, inimigos) for r in redes]

# MÃ©dia das decisÃµes
acao_final = {
    'mover_x': np.mean([a['mover_x'] for a in acoes]),
    'mover_y': np.mean([a['mover_y'] for a in acoes]),
    'atacar': sum([a['atacar'] for a in acoes]) >= 2,
    'fugir': sum([a['fugir'] for a in acoes]) >= 2
}
```

---

## ğŸ“š ReferÃªncias TÃ©cnicas

### FunÃ§Ãµes de AtivaÃ§Ã£o

- **Sigmoid**: SaÃ­da 0-1, suave
- **Tanh**: SaÃ­da -1 a 1, centrada
- **ReLU**: Linear positiva, rÃ¡pida

### InicializaÃ§Ã£o Xavier

```python
limite = sqrt(6 / (neurÃ´nios_entrada + neurÃ´nios_saÃ­da))
pesos = random_uniform(-limite, limite)
```

### SeleÃ§Ã£o por Torneio

1. Escolhe K candidatos aleatÃ³rios
2. Retorna o melhor do grupo
3. Mais justo que seleÃ§Ã£o pura

---

## ğŸš€ PrÃ³ximos Passos

1. âœ… Sistema de rede neural implementado
2. âœ… Algoritmo genÃ©tico pronto
3. â³ Integrar com simulaÃ§Ã£o
4. â³ Interface de treinamento
5. â³ VisualizaÃ§Ã£o de comportamento
6. â³ Sistema de aprendizado contÃ­nuo

---

**VersÃ£o:** 1.0  
**Data:** 17 de outubro de 2025  
**Status:** Pronto para integraÃ§Ã£o
